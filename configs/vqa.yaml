dataset:
  vqa_rad:
    data_dir: './datasets/VQA-RAD'
  slake:
    data_dir: './datasets/SLAKE'

vqa_root: './datasets/mscoco/'
vg_root: './datasets/visual-genome/'
train_files: ['vqa_train','vqa_val','vg_qa']
ann_root: 'annotation'

pretrained: 'checkpoints/model_base_vqa.pth'

vit: 'base'
batch_size_train: 16 
batch_size_test: 32 
vit_grad_ckpt: False
vit_ckpt_layer: 0
init_lr: 1e-5
image_size: 480

k_test: 128
inference: 'generate'

weight_decay: 0.05
min_lr: 0
max_epoch: 130
